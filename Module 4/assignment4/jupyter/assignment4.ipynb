{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d76a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc521b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2551 files found in easy_ham\n",
      "250 files found in hard_ham\n",
      "Invalid file from spam, encoding error\n",
      "Invalid file from spam, encoding error\n",
      "Invalid file from spam, encoding error\n",
      "Invalid file from spam, encoding error\n",
      "Invalid file from spam, encoding error\n",
      "496 files found in spam\n"
     ]
    }
   ],
   "source": [
    "easy_ham = []\n",
    "hard_ham = []\n",
    "spam = []\n",
    "\n",
    "def get_files(dir):\n",
    "    files = []\n",
    "    for filename in glob.glob(dir+'\\*'):\n",
    "        try:\n",
    "            with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "                files.append(f.read())\n",
    "        except:\n",
    "            print(\"Invalid file from {}, encoding error\".format(dir))\n",
    "            \n",
    "    print('{} files found in {}'.format(len(files), dir))\n",
    "    return np.array(files)\n",
    "            \n",
    "x_easy_ham = get_files('easy_ham')\n",
    "x_hard_ham = get_files('hard_ham')\n",
    "x_spam = get_files('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12af710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_header(mail):\n",
    "    # Filter all msg before Cc: if present\n",
    "    mail = mail.split('Cc:')\n",
    "    if (len(mail) == 1): # removed header did not worked, continuying the filtering\n",
    "        pass\n",
    "    else:\n",
    "        mail = mail[1]\n",
    "        \n",
    "    print(len(mail))\n",
    "    print(mail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8bfd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepocessing data : filter header\n",
    "import re\n",
    "str_ = x_easy_ham[0]\n",
    "remove_header(str_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c3cc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ham = np.concatenate((x_easy_ham, x_hard_ham))\n",
    "y_ham = np.ones(len(x_ham))\n",
    "y_spam = np.ones(len(x_spam)) -2\n",
    "\n",
    "# Run program on easy ham vs spam\n",
    "x_ham_spam = np.concatenate((x_ham, x_spam))\n",
    "y_ham_spam = np.concatenate((y_ham, y_spam))\n",
    "\n",
    "x_easy_spam = np.concatenate((x_easy_ham, x_spam))\n",
    "x_hard_spam = np.concatenate((x_hard_ham, x_spam))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ham_spam, y_ham_spam, test_size=0.25, random_state=16)\n",
    "\n",
    "# Run program on hard ham vs spam\n",
    "#hamtrain, hamtest = train_test_split(x_easy_ham, y_ham, test_size=0.3)\n",
    "#spamtrain, spamtest = train_test_split(x_spam, y_spam, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2cfa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5496b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "\n",
    "# vectorize the documents based on the vocabulary given by the ham and pam\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# tokenize\n",
    "x_train_vec = vectorizer.fit_transform(x_train)\n",
    "x_test_vec = vectorizer.transform(x_test)                                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc750757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Starting hyperoptimization for Multinomial ..\n",
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n",
      "[!] Best estimator MultinomialNB(alpha=0.1) \n",
      "[*] Starting hyperoptimization for Bernoulli ..\n",
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "[!] Best estimator BernoulliNB(alpha=0.001, binarize=1) \n"
     ]
    }
   ],
   "source": [
    "# Trainning on ham easy and spam and hyper optimization\n",
    "\n",
    "param_grid_nb_multi = {\n",
    "    'alpha': [1,0.1,0.01,0.001,0.0001,0]\n",
    "}\n",
    "param_grid_nb_bernoulli = {\n",
    "    'alpha': [1,0.1,0.01,0.001,0.0001,0],\n",
    "    'binarize': [1, 0.8, 0.5, 0.3, 0.1, 0.001]\n",
    "}\n",
    "\n",
    "print(\"[*] Starting hyperoptimization for Multinomial ..\")\n",
    "nbMultinomial_grid = GridSearchCV(estimator=MultinomialNB(), param_grid=param_grid_nb_multi, verbose=1, cv=10, n_jobs=-1).fit(x_train_vec, y_train)\n",
    "print(\"[!] Best estimator {} \".format(nbMultinomial_grid.best_estimator_))\n",
    "\n",
    "print(\"[*] Starting hyperoptimization for Bernoulli ..\")\n",
    "nbBernoulli_grid = GridSearchCV(estimator=BernoulliNB(), param_grid=param_grid_nb_bernoulli, verbose=1, cv=10, n_jobs=-1).fit(x_train_vec, y_train)\n",
    "print(\"[!] Best estimator {} \".format(nbBernoulli_grid.best_estimator_))\n",
    "\n",
    "multinomial_nb = nbMultinomial_grid.best_estimator_\n",
    "bernoulli_nb = nbBernoulli_grid.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_nb = MultinomialNB().fit(x_train_vec, y_train)\n",
    "bernoulli_nb = BernoulliNB(binarize=1).fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2ef885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, x_test_vec_, y_test_):\n",
    "    acc = 0\n",
    "    for i in range(0, x_test_vec_.shape[0]):\n",
    "        sample = x_test_vec_[i, :]\n",
    "        pred = model.predict(sample)\n",
    "        if pred == y_test_[i]:\n",
    "            acc+=1/x_test_vec_.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a959372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(model, x_test_vec_, y_test_):\n",
    "    y_pred = []\n",
    "    for i in range(0, x_test_vec_.shape[0]):\n",
    "        sample = x_test_vec_[i, :]\n",
    "        pred = model.predict(sample)\n",
    "        y_pred.append(pred)\n",
    "    y_pred = np.array(y_pred)\n",
    "    print(confusion_matrix(y_test_, y_pred), \": is the confusion matrix\")\n",
    "    print(round(accuracy_score(y_test_, y_pred),4), \": is the accuracy score\")\n",
    "    print(round(precision_score(y_test_, y_pred), 4), \": is the precision score\")\n",
    "    print(round(recall_score(y_test_, y_pred), 4), \": is the recall score\")\n",
    "    print(round(f1_score(y_test_, y_pred), 4), \": is the f1 score\") # f1 is a mix of accuracy and recall\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85d42112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for multinomal All-Ham vs Spam \n",
      "[[117   4]\n",
      " [  3 701]] : is the confusion matrix\n",
      "0.9915 : is the accuracy score\n",
      "0.9943 : is the precision score\n",
      "0.9957 : is the recall score\n",
      "0.995 : is the f1 score\n",
      "\n",
      "\n",
      "Accuracy for bernoulli All-Ham vs Spam\n",
      "[[116   5]\n",
      " [  1 703]] : is the confusion matrix\n",
      "0.9927 : is the accuracy score\n",
      "0.9929 : is the precision score\n",
      "0.9986 : is the recall score\n",
      "0.9958 : is the f1 score\n"
     ]
    }
   ],
   "source": [
    "#i = 40\n",
    "#sample = x_test_vec[i, :]\n",
    "#pred = multinomial_nb.predict(sample)\n",
    "\n",
    "#acc = get_accuracy(multinomial_nb, x_test_vec, y_test)\n",
    "#acc_bernoulli = get_accuracy(bernoulli_nb, x_test_vec, y_test)\n",
    "\n",
    "print(\"Accuracy for multinomal All-Ham vs Spam \")\n",
    "get_info(multinomial_nb, x_test_vec, y_test)\n",
    "print(\"\\n\\nAccuracy for bernoulli All-Ham vs Spam\")\n",
    "get_info(bernoulli_nb, x_test_vec, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7407fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Accuracy for multinomal All-Ham vs Spam \")\n",
    "get_info(multinomial_nb, x_test_vec, y_test)\n",
    "print(\"\\n\\nAccuracy for bernoulli All-Ham vs Spam\")\n",
    "get_info(bernoulli_nb, x_test_vec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525fd6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
