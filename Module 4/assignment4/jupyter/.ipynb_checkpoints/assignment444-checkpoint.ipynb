{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d76a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc521b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2410 files found in easy_ham\n",
      "221 files found in hard_ham\n",
      "418 files found in spam\n"
     ]
    }
   ],
   "source": [
    "easy_ham = []\n",
    "hard_ham = []\n",
    "spam = []\n",
    "\n",
    "def get_files(dir):\n",
    "    files = []\n",
    "    for filename in glob.glob('/Users/nathanhaudot/Desktop/jupyter/'+dir+'/*'):\n",
    "        try:\n",
    "            with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "                files.append(f.read())\n",
    "        except:\n",
    "            pass\n",
    "            # print(\"Invalid file from {}, encoding error\".format(dir))\n",
    "            \n",
    "    print('{} files found in {}'.format(len(files), dir))\n",
    "    return np.array(files)\n",
    "            \n",
    "x_easy_ham = get_files('easy_ham')\n",
    "x_hard_ham = get_files('hard_ham')\n",
    "x_spam = get_files('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c3cc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_ham = np.concatenate((x_easy_ham, x_hard_ham))\n",
    "y_ham = np.ones(len(x_easy_ham))\n",
    "y_spam = np.ones(len(x_spam)) -2\n",
    "\n",
    "# Run program on easy ham vs spam\n",
    "x_ham_spam = np.concatenate((x_easy_ham, x_spam))\n",
    "y_ham_spam = np.concatenate((y_ham, y_spam))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ham_spam, y_ham_spam, test_size=0.25, random_state=16)\n",
    "\n",
    "# Run program on hard ham vs spam\n",
    "\n",
    "\n",
    "x_ham_spam\n",
    "\n",
    "#hamtrain, hamtest = train_test_split(x_easy_ham, y_ham, test_size=0.3)\n",
    "#spamtrain, spamtest = train_test_split(x_spam, y_spam, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5496b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "\n",
    "# vectorize the documents based on the vocabulary given by the ham and pam\n",
    "vectorizer = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "x_train_vec = vectorizer.fit_transform(x_train)\n",
    "x_test_vec = vectorizer.transform(x_test)                                   \n",
    "# summarize\n",
    "#print(vectorizer.vocabulary_)\n",
    "# encode document\n",
    "x_train = vectorizer.transform(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc750757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainning on ham easy and spam\n",
    "\n",
    "multinomial_nb = MultinomialNB().fit(x_train, y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
